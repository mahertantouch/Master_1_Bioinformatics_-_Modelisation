{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe0b3d-64ba-4560-8b2b-ba61d149085f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation 9-5-24 Cours Deep-Life TME-solo-2\n",
    "\n",
    "Nom: \n",
    "\n",
    "Prénom:\n",
    "\n",
    "Numéro Etudiant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0e2ff8-9454-462e-82a5-bb5ffff77006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0163aa-879e-4ca7-89eb-eddc62ef0f2f",
   "metadata": {},
   "source": [
    "# Consignes\n",
    "\n",
    "## Document à rendre\n",
    "Le Jupyter Notebook est le document à rendre. Il doit être rendu de manière à ce qu'il soit facile à lire, et qu'il soit facile de\n",
    "repérer et de lire vos réponses. Si ce n'est pas le cas, des points vous seront retirés, ceci pouvant aller jusqu'à l'intégralité \n",
    "des points pour la question.\n",
    "    \n",
    "\n",
    "## Documents autorisés\n",
    "\n",
    "\n",
    "Vous n'êtes pas autorisé à utiliser d'autres ressources que celles qui vous sont fournies sur Moodle. Vous pouvez utiliser les TME que vous avez déjà mis sur Moodle, c'est-à-dire les rendus de TME. Vous pouvez utiliser vos propres machines et vos notes de cours (pdf, document word, etc.) et notes manuscrites.\n",
    "\n",
    "Vous ne pouvez pas utiliser Internet autrement que pour accéder à Moodle. Si cette consigne n'est pas respectée,\n",
    "cela signifie automatiquement un zéro pour votre copie. Si jupyter notebook ne fonctionne pas vous pouvez utiliser Colab.\n",
    "\n",
    "\n",
    "Aidez-vous de la fonction help(***), où *** doit être remplacé par l'objet,la fonction... pour lequel vous souhaitez avoir plus d'informations.\n",
    "\n",
    "## Indication sur les fonctions et classes qui peuvent être utilisées:\n",
    "\n",
    "- torch.nn.functional.relu\n",
    "- torch.sigmoid\n",
    "- nn.Linear\n",
    "- torch.sigmoid\n",
    "- matplotlib.pyplot.scatter\n",
    "- numpy.linspace\n",
    "\n",
    "#### Le bareme est donné à titre indicatif\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d740ce-116b-4282-bd4b-c5e42ecc602a",
   "metadata": {},
   "source": [
    "## Objectif du TME\n",
    "\n",
    "Dans ce TME-solo nous cherchons des architectures qui peuvent etre utiles pour plusieurs taches, \n",
    "nous allons entrainer un autoencodeur dont l'encodeur servira soit comme initialisation (peu d'entrainement) pour \n",
    "l'entrainement d'un classifieur sur le jeu de donnée Fashion Mnist.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe71b1-7f97-43de-9494-3e784494b31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tme_solo as tme\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93af808e-53a0-4cab-9623-20d8563a6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55853d5-8809-42c3-b882-ca15958bb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_fashion=datasets.FashionMNIST(root=\"data\", train=True,transform=transforms.ToTensor(), download= True)\n",
    "test_data_fashion=datasets.FashionMNIST(root=\"data\", train=False,transform=transforms.ToTensor(), download= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfdd862-f9ff-4a0b-9a0f-bca6044ab586",
   "metadata": {},
   "source": [
    "### Q1 \n",
    "#### A quoi correspondent les echantillons de training_data_fashion? inscrivez vos reponde dans uen fonction Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24b9fb47-c2ef-410b-8501-01d4427911fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1(training_data_fashion):\n",
    "    '''entrée: training_data_fashion\n",
    "       sortie: votre reponse'''\n",
    "\n",
    "    return votre_reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae27be-dc5b-47fe-8592-8d58e82b0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tme.question1(training_data_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206d636-ab72-42bc-a1a2-2d8bbe98a80e",
   "metadata": {},
   "source": [
    "### Q2  \n",
    "\n",
    "#### Créez un jeu de données `training_data_small`, qui ne contient qu’environ 1/10 des données de `training_data_fashion`, en vous assurant de respecter plus ou moins les proportions des données par classe de `training_data_fashion`.  \n",
    "\n",
    "#### Le jeu de données `training_data_small` que vous retournerez est une liste constituée de couples (image, label), où l’image est un tenseur (`torch.Tensor`) et le label un entier correspondant à la classe de l’image.  \n",
    "\n",
    "#### Faites de même pour `test_data_fashion` : créez un jeu de données `test_data_small` ne contenant qu’environ 1/10 des données de `test_data_fashion`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3b681ca-e66f-44fd-a210-8b623386ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2(training_data_fashion,test_data_fashion):\n",
    "    ''' entrée training_data_fashion: le train de FashionMnist\n",
    "        entrée test_data_fashion: le test de FashionMnist\n",
    "        sortie training_data_small: le jeu de donné tran qui contient 1/10 du train de FashionMnist\n",
    "        sortie test_data_small: le jeu de donné tran qui contient 1/10 du test de FashionMnist'''\n",
    "    \n",
    "    return training_data_small,test_data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9fef6-2cef-442a-be55-76e1908038ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data_small,test_data_small=tme.question2(training_data_fashion,test_data_fashion)\n",
    "len(training_data_small)/len(training_data_fashion),len(test_data_small)/len(test_data_fashion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5203a-9b99-4d18-80cf-de32202e6a80",
   "metadata": {},
   "source": [
    "# Partie I: Autoencodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6356ca-9a79-4289-bdc6-2ef08c65e45b",
   "metadata": {},
   "source": [
    "### Q2 (3pts)\n",
    "#### Implémentez un auto-encodeur dont le latent sera de taille latent_dims (un entier qui est un paramètre de l'encodeur) et qui sera constitué de deux blocs: \n",
    "\n",
    "#### - un encodeur constitué de :\n",
    "####  - un layer linéaire de taille la dimension d'entrée et de sortie 128 avec une fonction d'activation ReLU\n",
    "####  - un layer linéaire de taille 128 en entrée avec une fonction d'activation ReLU\n",
    "  \n",
    "####  - un décodeur constitué de :\n",
    "####  - un layer linéaire de taille de sortie 128 avec une fonction d'activation ReLU\n",
    "####  - un layer linéaire de taille d'entrée 128 avec une activation sigmoide\n",
    "\n",
    "#### Dans la description précédente, toutes les tailles ne sont pas précisées, c'est à vous de compléter les données manquantes de taille. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c87e3-b8af-4355-b5f2-b2f614fefcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Les ? sont à compléter\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dims,input_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(?, 128)\n",
    "        self.linear2 = nn.Linear(?, ?)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(?)\n",
    "        x=self.linear2(?)\n",
    "        x=F.relu(?)\n",
    "        return x\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims,input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(?, ?)\n",
    "        self.linear2 = nn.Linear(?, ?)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(?)\n",
    "        z = torch.sigmoid(?)\n",
    "        return z.reshape((-1, 1, input_dim, input_dim))\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims,input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(?,?)\n",
    "        self.decoder = Decoder(?,?)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ???\n",
    "        return ???\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e2ef92-21d3-4a64-8644-9493b43e1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = 2\n",
    "input_dim = 28\n",
    "autoencoder = tme.Autoencoder(latent_dims,input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba6b85-f7e5-4c0c-b1bc-b07c9a6f3f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56786aa7-68b3-408b-b42b-4daaa133a932",
   "metadata": {},
   "source": [
    "### Q4 Ajout de bruit à l'autoencodeur\n",
    "\n",
    "#### Nous allons bruiter les images en entrée de `training_data_small`. Pour ce faire, nous définissons une fonction de bruitage qui prend en entrée une image (sous la forme d'un tenseur) et retourne une version bruitée de cette image, sous la forme d'un tenseur de la même taille que l'image d'entrée.  \n",
    "\n",
    "#### Implémentez la fonction `noise` avec comme niveau de bruit $p$, où $p$ est compris entre 0 et 1. Pour chaque image $x$ au format 'tenseur', choisissez aléatoirement un nombre $NP = p \\times N$ de pixels, où $N$ est le nombre total de pixels de l'image, et changez leur valeur en 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0331f6-fc4f-4b48-8044-71c1ff80daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(x,p=0.1):\n",
    "    '''entrée x: image d'entrée\n",
    "       entrée p: niveau de bruit\n",
    "       sortie image_bruitee: image bruitée\n",
    "    '''\n",
    "   \n",
    "    return image_bruitee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef4bbc9-c80d-4c49-90dd-189543751b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'une image bruitée\n",
    "x=test_data_small[10][0].unsqueeze(dim=0)\n",
    "y=tme.noise(x)\n",
    "image=transforms.ToPILImage()(y.squeeze())\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59887526-03e0-4bb3-bd1e-b1659d59ea07",
   "metadata": {},
   "source": [
    "### Q5 \n",
    "#### Creer un jeu de donnée `training_data_small_noised` de la taille de `training_data_small` qui contient les image bruitées et leur labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad2c41b7-b7f4-4121-a5af-260e44b4cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question5(training_data_small,p=0.1):\n",
    "    ''' entrée training_data_small: 1/10 du train de FashionMnist\n",
    "        entrée p: niveau de bruit par defaut 0.1\n",
    "        sortie training_data_small_noized: les couples d'images et label issus de training_data_small mais avec des images bruitées.\n",
    "    '''\n",
    "        \n",
    "    return training_data_small_noised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d981b6f6-e50b-47e6-b548-4afdedd79533",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_small_noised=tme.question5(training_data_small,p=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab45759-2adc-441e-87ef-87994362839a",
   "metadata": {},
   "source": [
    "### Q6 Entraînement de l'autoencodeur\n",
    "\n",
    "#### Le but est d'entraîner l'autoencodeur à débruiter les images qu'il a en entrée. Considérez un niveau de bruit par défaut de $ p = 0.1 $. Faites des batchs de taille 128 et entraînez votre autoencodeur pendant 20 epochs avec comme loss la Mean Squared Error et comme dimension de latent: latent_dims = 2 . \n",
    " \n",
    "#### Représentez l'évolution de la loss au cours de l'entraînement.\n",
    "\n",
    "#### Compléter la fonction train dans votre fichier python ainsi que la fonction question6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d144f38-af94-4078-b03e-d19893b1810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compléter les ??\n",
    "\n",
    "def train(autoencoder, data, epochs=20, lr=0.001):\n",
    "    opt = torch.optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        loss_e = ??\n",
    "        for x, y in data:\n",
    "            ???\n",
    "            loss_e += loss.to('cpu').detach().numpy()\n",
    "        losses.append(loss_e/len(data))\n",
    "    return autoencoder, losses\n",
    "\n",
    "\n",
    "def question6(training_data_small_noized,latent_dims,input_dim,batch_size=128, epochs=20, lr=0.001):\n",
    "    \n",
    "    data=torch.utils.data.DataLoader(??)\n",
    "    autoencoder = Autoencoder(latent_dims,input_dim)\n",
    "    autoencoder, losses = train(autoencoder, data,epochs=20,lr=0.001)\n",
    "    plt.plot(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accd8516-29ff-4e44-a55c-91ae51f59a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tme.question6(training_data_small_noized,autoencoder,latent_dims,input_dim,batch_size=128, epochs=20, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f306e-11c1-48fd-a311-9b7c8a5aebb7",
   "metadata": {},
   "source": [
    "### Q7  \n",
    "\n",
    "#### Nous allons maintenant tester les hyperparamètres qui entrent en jeu dans l'entraînement de l'encodeur, en particulier le learning rate et la dimension latente `latent_dims`.  \n",
    "\n",
    "#### Pour ce faire, nous vous demandons de découper `training_data_small_noised` en deux, en réservant 10 % des données pour la validation des hyperparamètres tout en respectant plus ou moins les proportions des données par classe. Creer un fonction question7 qui fait cela.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4573bd-edae-4d14-9a7e-533b3c336aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question7(training_data_small_noized):\n",
    "    '''entré training_data_small_noized: le jeu de donnée bruité\n",
    "       sortie train: 90% du jeu de donnée training_data_small_noized\n",
    "       sortie valid: 10% du jeu de donnée training_data_small_noized'''\n",
    "    \n",
    "    return train,valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ef8037-c3f4-4343-b785-61823d7587d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, valid1= tme.question7(training_data_small_noized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba05ae2-f6de-48dc-939c-96b8e88adfcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning Rate  \n",
    "\n",
    "#### La méthode d'optimisation  \n",
    "\n",
    "#### `torch.optim.Adam(autoencoder.parameters(), lr=lr)` ou `torch.optim.SGD(autoencoder.parameters(), lr=lr)`  fait apparaître un hyperparamètre `lr`, appelé **learning rate**. Il contrôle la vitesse de la descente de gradient en augmentant ou en réduisant la taille des pas effectués à chaque étape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ee5a3-a96f-46c5-bf24-e2e143e22d0b",
   "metadata": {},
   "source": [
    "### Q8  \n",
    "\n",
    "#### Nous effectuons la recherche d'hyperparamètres : entraînez l'autoencodeur pour des dimensions latentes `latent_dims` prenant des valeurs entre 2 et 10, espacées de 2, et un learning rate entre $ 0.0005$ et $ 0.0015 $, espacés de 3.  \n",
    "\n",
    "#### Évaluez chacun des modèles sur le jeu de données de validation et retournez une liste contenant les hyperparamètres ainsi que la valeur de la loss du modèle entraîné sur le jeu de données de validation. Le faire dans la fonction question8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74f63a-46b4-43fe-a524-ff961d43c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question8(train1,input_dim,batch_size=128, epochs=20): \n",
    "   ''' entrée train1: le jeu de donnée train qui correspond à 90% de training_data_small_noized\n",
    "        entrée valid1: le jeu de donnée de validation\n",
    "        entrée input_dim: la longeur des images\n",
    "        entrée batch_size: la taille des batch\n",
    "        entrée epochs: le nombre d'epochs\n",
    "        sortie losses: une liste pour chaque hyperparametre contenant une sous list [latent,lr,loss] \n",
    "        latent étant la taille du latent, lr le learning rate et \n",
    "        loss étant la valeur de la loss sur le jeu de donnée de validation pource jeu d'hyperparamètres\n",
    "    '''\n",
    "    ouput=[]\n",
    "    for ??:\n",
    "        ??\n",
    "        ouput.append([latent,lr,tot])\n",
    "\n",
    "    return output\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83bb2115-d61c-41d4-938e-bb6faa781829",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "losses=tme.question8(train1,valid1,input_dim,batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac19c6-4924-4516-894a-16db9761c53f",
   "metadata": {},
   "source": [
    "### Q9  \n",
    "\n",
    "#### Renvoyez le couple d'hyperparamètres ayant la loss la plus basse sur la validation dans la fonction `best_hyper_param' .\n",
    "\n",
    "#### Réentraînez l'auto-encodeur avec ces hyperparamètres sur `training_data_small_noised` et renvoyez l'encodeur dans un modèle `encodeur_trained`. Le faire dans la fonction question9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e54d0796-932f-497f-892f-8b121376cad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_hyper_param(losses):\n",
    "    '''entrée losses: les tuples hyperparamètres et valeur de la loss\n",
    "       sortie latent_dims_val,lr_val: les hyperparamètres correspondant à la loss la plus basse'''\n",
    "    \n",
    "    return latent_dims_val,lr_val\n",
    "\n",
    "\n",
    "\n",
    "def question9(training_data_small_noised,input_dim,latent_dims_val,lr_val,batch_size=128, epochs=20):\n",
    "    ''' \n",
    "        sortie encodeur_trained: l'encodeur de l'autoencodeur entrainé sur training_data_small_noised avec les hyperparamètres optimaux.\n",
    "    '''\n",
    "    \n",
    "    return encodeur_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339773d-f75f-4f04-955b-3b998fdbcb0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dims_val,lr_val=tme.best_hyper_param(losses)\n",
    "encodeur_trained=tme.question9(training_data_small_noised,input_dim,latent_dims_val,lr_val,batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd562f91-faff-4adb-87f5-aa2cca07e277",
   "metadata": {},
   "source": [
    "### Q10  \n",
    "\n",
    "#### Nous allons réexploiter l'encodeur entraîné précédemment pour la tâche de classification qui consiste à prédire le label associé à une image.  \n",
    "\n",
    "#### Implémentez un réseau de neurones que nous appellerons `head`, qui servira de sortie à `encodeur_train` pour la tâche de classification. `head` est constitué d'un layer linéaire prenant en entrée la dimension `latent_dims`.  \n",
    "\n",
    "#### Implémentez un réseau de neurones `classif_pretrained`, qui est la composition de `encodeur_train`, puis de `head`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d07d0b-814f-4433-9d00-2c665fe15ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compléter les ???\n",
    "class head(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        ???\n",
    "\n",
    "    def forward(self, x):\n",
    "        ???\n",
    "  \n",
    "        return x\n",
    "\n",
    "\n",
    "class classif_pretrained(nn.Module):\n",
    "    def __init__(self,encodeur_trained, latent_dims):\n",
    "        super(classif_pretrained, self).__init__()\n",
    "        self.layer1= encodeur_trained\n",
    "        self.layer2= head(latent_dims)\n",
    "    \n",
    "    def forward(self, x): \n",
    "          ???\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9eae71af-eefc-40cf-88fc-ef9f3dbf139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_pretrained= tme.classif_pretrained(encodeur_trained,latent_dims_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabef872-4ac6-49e3-8978-cd3f3dc3c00d",
   "metadata": {},
   "source": [
    "### Q11  \n",
    "\n",
    "#### Entraînez le réseau `classif` sur `training_data_small` avec un `batch_size` de 128, avec l'optimiseur Stochastic Gradient Descent (torch.optim.SGD), et un learning rate que vous déterminerez et justifierez. Représentez l'évolution de la loss au cours de l'entraînement. Les boucles d'entrainenemt se feront dans la fonction `train1` et l'appel à cette fonction et la representation de la loss dans `question11`\n",
    "\n",
    "#### Utilisez un nombre d'epochs égal à 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c09908-0ee9-4292-90f5-188651f1aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train1(classif,data,epochs=5):\n",
    "    ????\n",
    "    \n",
    "    return losses\n",
    "\n",
    "def question11(classif,training_data_small,batch_size=128, epochs=5):\n",
    "    ???\n",
    "    losses = train1(classif_trained, data,epochs=20)\n",
    "    plt.plot(losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576af5f5-0e95-417f-b3b3-3176669435c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tme.question11(classif_pretrained,training_data_small,batch_size=128, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d3af2c-5b1c-4987-af51-1b8f4eab47cb",
   "metadata": {},
   "source": [
    "### Q12  \n",
    "\n",
    "#### Entraînez un réseau de neurones `classif`, ayant la même architecture que le réseau `classif_pretrained`, mais dont l'encodeur n'est pas entraîné. Autrement dit, l'encodeur est une instance de `Encoder` qui n'a pas été entraînée, contrairement à `encodeur_trained`.  \n",
    "\n",
    "#### L'entraînement s'effectue sur `training_data_small` avec un `batch_size` de 128, l'optimiseur Stochastic Gradient Descent, et un learning rate que vous déterminerez et justifierez.  \n",
    "\n",
    "#### Utilisez un nombre d'epochs égal à 5.  \n",
    "\n",
    "#### Écrivez une fonction `score` (accuracy) qui retourne le pourcentage de prédictions correctes sur le jeu de données de test. Comparez le score entre `classif_trained` et `classif`. Représentez l'évolution de la loss au cours de l'entraînement de `classif` et retourner la comparison l'accuracy des deux modèles dans la fonction `question12`.\n",
    "\n",
    "#### Que conclure ? Imprimez votre réponse au sein de `question12`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6002320c-9981-4039-abea-932ecb336785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class classif(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(classif, self).__init__()\n",
    "        ???\n",
    "    \n",
    "    def forward(self, x): \n",
    "        ???\n",
    "        return x\n",
    "\n",
    "def train2(classif,data, epochs=5, lr=0.001):\n",
    "    ????\n",
    "    \n",
    "    return losses\n",
    "    \n",
    "def score(model,test_data_small):\n",
    "    ''' entree model: le modèle entrainé pour le quel on veut calculer le pourcentage de prediction correctes\n",
    "        entree test_data_small: le jeu de donnée sur lequel on calcul cette accuracy\n",
    "        sortie score: le pourcentage de prediction correctes\n",
    "    '''\n",
    "    return score\n",
    "\n",
    "def question11(classif,training_data_small,batch_size=128, epochs=5):\n",
    "    ???\n",
    "    losses = train2(classif, data,epochs=20)\n",
    "    plt.plot(losses)\n",
    "    prin('reponse a la question')\n",
    "    return score(classif_trained,test_data_small)>score(classif,test_data_small)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758b330-b433-456e-b304-acde7ab974bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reponse=tme.question11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca58f4-f4fd-4f05-9524-6f46a04a61f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
