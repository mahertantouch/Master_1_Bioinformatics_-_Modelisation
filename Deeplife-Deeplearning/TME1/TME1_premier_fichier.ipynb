{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b37f51-fd4c-41ca-8bcc-15e00fdf7a42",
   "metadata": {},
   "source": [
    "## Rendu du TME: Consignes\n",
    "\n",
    "Mettez vous en groupe de 2 ou 3 et ne rendez qu'un fichier python par groupe. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Créez un document tme1.py. Chaque question nécessite d'écrire une fonction. S'il vous est demandé d'afficher des informations, utilisez print au sein de votre fonction pour les afficher lors de l'appel de cette fonction. Après chaque question, un appel de la fonction est fait dans une cellule en dessous du Jupyter Notebook.\n",
    "\n",
    "Le Jupyter Notebook ne sera pas conservé et seul le fichier tme1.py sera accepté comme réponse à cette évaluation et à \n",
    "déposer sur Moodle. Vous pouvez donc modifier comme vous le souhaitez votre Jupyter Notebook, par exemple en ajoutant \n",
    "des cellules pour faire des essais. Néanmoins, faites attention : assurez-vous que vos fonctions soient bien chargées \n",
    "correctement et qu'elles ne dépendent que des variables déjà instanciées dans la version du TME que vous venez de télécharger \n",
    "sur Moodle et que vous êtes en train de lire.\n",
    "\n",
    "Enfin, n'hésitez pas à **utiliser des ressources en ligne sur https://pytorch.org/** si vous avez un doute sur ce que fait une fonction. Il est important d'apprendre à se documenter sur ce que font les fonctions en autonomie et à découvrir de nouvelles fonctions ou classes.\n",
    "\n",
    "## Documents autorisés\n",
    "\n",
    "Vous pouvez utiliser toutes les ressources. \n",
    "\n",
    "\n",
    "Vous avez une semaine ne plus pour rendre le TME. \n",
    "\n",
    "Si vou rencontrez un problème avec le rendu du TME, envoyez un mail à gregoireserper@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4578f9-f61a-4a39-975e-2c4ef090c135",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "A mettre dans votre fichier tme1.py\n",
    "\n",
    "Noms: \n",
    "\n",
    "Prénoms:\n",
    "\n",
    "Numéro Etudiants:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74730f0-b03c-472f-b86f-04d44b2be01a",
   "metadata": {},
   "source": [
    "1. Les lignes autoreload permettent que l'environnement d'exécution du notebook recharge le fichier tme1.py à chaque modification;\n",
    "2. N'hésitez pas à \"restart kernel\" de temps en temps et à ré-exécuter l'ensemble du notebook;\n",
    "3. Il faudra soumettre uniquement le fichier tme1.py qui contiendra en première ligne les noms de ses auteurs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513c967-2562-46fe-9c61-6596f2056607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tme1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddca641-aa14-4884-8423-9c09adf58b10",
   "metadata": {},
   "source": [
    "# TME 1: An Introduction to Deep Learning in Life Sciences\n",
    "## Tenseur, jeux de données et transformations\n",
    "<!--\n",
    "Introduction à pytorch \n",
    "Reference: https://pytorch.org/tutorials/beginner/basics/intro.html\n",
    "utile pour moi pour Markdown https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#emphasis\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "125e80aa-cf0c-4f8f-9179-a9c02113737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d77a44-f7c9-4148-b761-53ce3101c6d0",
   "metadata": {},
   "source": [
    "# Introduction aux Tenseurs\n",
    "But: Se familiariser avec les tenseurs et pytorch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90785f-b7ba-4c28-b401-be35e612df47",
   "metadata": {},
   "source": [
    "## Q1: Telechargez le dataset MNIST et comprendre les données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d517ef1-a095-4689-b487-3ed71497b74a",
   "metadata": {},
   "source": [
    "Aidez vous de la reference suivante \n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html\n",
    "\n",
    "\n",
    "1. Creez une variable dataset qui contient le dataset MNIST. \n",
    "2. Que contient ce jeux de donnée? \n",
    "Affichez img=dataset[0][0] (utiliser plt.imshow( \n",
    "3. Quelles sont les dimensions d'un échantillon dans le jeu de données ?\n",
    "4. Ces dimensions correspondent-elles à celles d'une image ?\n",
    "\n",
    "Ecrivez votre reponse dans une fonction question1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a36656fb-b8fe-488b-a76d-58e32238aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1():\n",
    "    '''\n",
    "    Imprimer votre réponse \n",
    "    Afficher l'image sous la forme d'une image\n",
    "    '''\n",
    "tme1.question1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbecb15-1343-4190-af95-b2463f625b91",
   "metadata": {},
   "source": [
    "## Les tenseurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b593a66-67b5-439c-8ae2-a52e095df689",
   "metadata": {},
   "source": [
    "<img src=\"mediumtensors.webp\" alt=\"Alternative text\" />\n",
    "\n",
    "Image prise de https://medium.com/@schartz/the-shape-of-tensor-bab75001d7bc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2538f78-a916-453b-8ec5-a9c899228d19",
   "metadata": {},
   "source": [
    "\n",
    "Vous pouvez vous aider des liens suivants pour la conversion\n",
    "https://pytorch.org/vision/stable/generated/torchvision.transforms.PILToTensor.html\n",
    "https://discuss.pytorch.org/t/pytorch-pil-to-tensor-and-vice-versa/6312\n",
    "\n",
    "et de cela pour la forme de\n",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.size.html\n",
    "ou de .shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f9889-96c6-4a35-93c4-b20e1cbbde31",
   "metadata": {},
   "source": [
    "### Les tenseurs: Définition formelle de tenseurs et contraction\n",
    "Mathématiquement, des tenseurs de taille K sont des tableaux\n",
    "$$t:[1,n_1]\\times [1,n_2]\\times \\ldots \\times [1,n_K]\\to \\mathbb{R}$$\n",
    "Ils sont notés $t_{i_1i_2\\ldots i_K}$ avec $i_1\\in [1,n_1]$, $i_2\\in [1,n_2]$, $\\ldots$, $i_K\\in [1,n_K]$.\n",
    "Une matrice est un cas particulier des tenseurs $M:[1,n_1]\\times [1,n_2]\\to \\mathbb{R}$.\n",
    "\n",
    "La généralisation de la multiplication matricielle est la multiplication des tenseurs. Deux tenseurs $t^{(1)}$ et $t^{(2)}$ de taille respective $K_1$ et $K_2$ se multiplient sur un de leurs indices respectifs $I_1$ et $I_2$ de la façon suivante:\n",
    "\n",
    "$$ t^{(1)}.t^{(2)}= \\sum_{\\alpha \\in [1,n_{I_1}^{(1)}]}t_{i_1.. \\alpha.. i_K}^{(1)}t_{i_1.. \\alpha.. i_K}^{(2)}$$\n",
    "\n",
    "quand $n_{I_1}^{(1)}=n_{I_2}^{(2)}$. $t^{(1)}.t^{(2)}$ is of size $K_1-1+K_2-1$.\n",
    "\n",
    "Cette multiplication s'étend à des collections d'indices:\n",
    "\n",
    "\n",
    "$$ t^{(1)}.t^{(2)}= \\sum_{\\alpha,\\beta \\in [1,n_{I_1}^{(1)}]\\times [1,n_{J_1}^{(1)}]}t_{i_1.. \\alpha\\beta .. i_K}^{(1)}t_{i_1.. \\alpha\\beta .. i_K}^{(2)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433fdc9c-47e2-4b66-85c6-6cb0fa7c216f",
   "metadata": {},
   "source": [
    "## Q2: Operations sur les tenseurs\n",
    "\n",
    "1. Definir un tenseur T de forme [1,3,3,3] ne contenant que des 1.\n",
    "    On considère deux copies de T:\n",
    "2. Fait la multiplication sur la dernière dimension du premier tenseur et la dernière dimension du deuxième\n",
    "3. Faire de meme pour la deuxieme du premier et la troisieme du deuxieme.\n",
    "   On considère trois copies de T:\n",
    "4. Stack 3 copies de T en un tenseur de taille [3,3,3,3], on appelle ce tenseur Y\n",
    "5. Reshape Y en une matrice [9,9]\n",
    "\n",
    "\n",
    "Vous pouvez vous aider des liens suivants:\n",
    "https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
    "https://pytorch.org/docs/stable/generated/torch.tensordot.html\n",
    "https://pytorch.org/docs/stable/generated/torch.einsum.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0627dbeb-29fa-48b2-b8f0-32b53b6b1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question2():\n",
    "    '''\n",
    "    Sortie:\n",
    "    T : le tenseur de la forme [1,3,3,3] ne contenant que des 1.\n",
    "    T1: la multiplication sur la dernière dimension du premier tenseur et la dernière dimension du deuxième\n",
    "    T2: la multiplication dela deuxieme dimension du premier et la troisieme dimension du deuxieme tenseur\n",
    "    Y: 3 copies de T stack les unes sur les autres\n",
    "    Z: Y sous la forme d'un matrice  [9,9]\n",
    "    \n",
    "    '''\n",
    "\n",
    "    return T,T1,T2,Y,Z\n",
    "tme1.question2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f9a28-9b7a-4fc7-bce0-a444c3b94043",
   "metadata": {},
   "source": [
    "# Decoupage train, test et sous jeux de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d05babc9-3cb9-4a41-8535-f85ec9898a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f864a403880>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data= datasets.MNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
    "test_data = datasets.MNIST(root=\"data\",train=False,download=True,transform=ToTensor())\n",
    "img=training_data[0][0]\n",
    "plt.imshow(img.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ddb91-0af2-47e8-8d4b-12c2ff8c4e1a",
   "metadata": {},
   "source": [
    "## Q3 MNIST : quelques informations indicatives sur le jeu de donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed2fe6f-77b8-42cd-8f9e-255e35f0df4e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. Quelle est la taille du jeu de données, c'est-à-dire combien y a-t-il de 'samples' ou \n",
    "échantillons sur le jeu de données train?\n",
    "2. Quelles sont les classes associées aux données ? Combien y en a-t-il ?\n",
    "\n",
    "Imprimez vos réponses en précisant dans votre code (ou en faisant appel) les fonctions qui vous ont permis de trouver ces réponses dans la fonction question3().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cbda773-8e67-4a1f-b049-a48f51fa2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3():\n",
    "    '''\n",
    "    Imprimez vos réponses en précisant dans votre code (ou en faisant appel) les fonctions qui vous ont permis de trouver ces réponses\n",
    "    '''\n",
    "tme1.question3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a4c29-c027-4d74-8c6f-d20657dbd500",
   "metadata": {},
   "source": [
    "### Q4 Extraire un sous jeu de donnée\n",
    "\n",
    "1. Extraire les données qui ont comme label la deuxième classe renvoyée par 'training_data.class_to_idx' et les mettre dans une variable mnist_small_torch \n",
    "2. Combien y a-t-il d'échantillons associés à cette classe ? Est-ce que ce nombre vous semble cohérent ? Justifiez votre réponse.\n",
    "\n",
    "\n",
    "Creer une fonction question4 qui imprime la réponse et votre justification et retourne mnist_small_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0c04b758-509b-4303-9991-608fc536dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question4(training_data):\n",
    "    ''' \n",
    "    Entrée: training_data le jeu de donnée train de Mnist\n",
    "    Sortie: \n",
    "    mnist_small_torch: le jeu de donné qui on comme label la deuxième classe qui est affichée par training_data.class_to_idx\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    return mnist_small_torch\n",
    "tme1.question4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fbe90-c4a3-4be3-bd4d-729f1d3d4b73",
   "metadata": {},
   "source": [
    "### Q5: Extraire les données de classe 7 et 9\n",
    "\n",
    "1. Écrire dans votre fichier tme1.py la fonction 'decoupage_torch' \n",
    "qui prend en entrée les listes training_data et test_data et retourne deux listes restrict_train, restrict_test, chaque liste étant constituée d'image de 7 ou de 9 et de leurs labels. \n",
    "\n",
    "Attention on modifie les classes: 7 qui devient 0 et 9 qui devient 1. On s'attend à ce que le vecteur de classe soit un vecteur (tenseur torch) soit un vecteur de 0 et 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43e8db9d-1832-4acf-aa62-0c306b979a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decoupage(training_data_list,test_data_list):\n",
    "    '''\n",
    "    Entrée:\n",
    "    training_data_list : la liste des couples (donnée,label) du trainset\n",
    "    test_data_list : la liste des couples (donnée,label) du testset\n",
    "\n",
    "    Sortie:\n",
    "    restrict_train : la liste des couples (donnée,label) du trainset pour les labels 7 et 9 \n",
    "    restrict_test : la liste des couples (donnée,label) du testset pour les labels 7 et 9 \n",
    "    '''\n",
    "\n",
    "    return restrict_train, restrict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2ea79-6b77-4dca-b1bd-416fe5904e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "restrict_train, restrict_test=tme1.decoupage(training_data_list,test_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974bb10e-fe51-42b5-975c-b72aedb3c36b",
   "metadata": {},
   "source": [
    "# Transformations et augmentations sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef28b8a-57bb-4d43-8a1c-0b080a189a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf955c54-b2d9-464e-88ab-a719b9ccb98d",
   "metadata": {},
   "source": [
    "Nous allons maintenant effectuer des transformation sur les données train. \n",
    "\n",
    "Les références pour cette question sont:\n",
    "1. https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#sphx-glr-auto-examples-transforms-plot-transforms-getting-started-py\n",
    "2. https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "\n",
    "Notre but est de comprendre le code suivant tiré d'une methode d'apprentissage auto-supervisé (ICA, BarlowTwins) https://github.com/facebookresearch/barlowtwins/blob/main/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecdf81-840e-440b-90b2-692d85845e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            GaussianBlur(p=1.0),\n",
    "            Solarization(p=0.0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_prime = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            GaussianBlur(p=0.1),\n",
    "            Solarization(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y1 = self.transform(x)\n",
    "        y2 = self.transform_prime(x)\n",
    "        return y1, y2\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189ca30-1728-4280-bd8b-2c70210e4b63",
   "metadata": {},
   "source": [
    "## Q6: Normaliser les données d'entrée\n",
    "\n",
    "1. Calculer la moyenne et l'écart-type des images de `restrict_train`. C'est-à-dire, on traite chaque pixel d'une image comme un scalaire, et on calcule la moyenne $\\mu$ et l'écart-type $\\sigma$ sur tous les pixels de toutes les images du jeu de données.  \n",
    "2. Créer un nouveau jeu de données qui contient les images centrées et réduites de `restrict_train`, c'est-à-dire qu'on retranche $\\mu$ et on divise par $\\sigma$ pour chaque image.  \n",
    "3. Définir une fonction `Normalize_dataset(dataset)` qui prend en entrée un jeu de données de tenseurs et donne en sortie le jeu de données normalisé au sens des points 1. et 2.  \n",
    "\n",
    "Indication: aidez vous de v2.Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf63f0-7af4-4c9c-8439-d4e5eb23fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Normalize_dataset(dataset):\n",
    "    ''' \n",
    "    Entrée:\n",
    "    Le jeu de donnée de tenseurs, c'est à dire un tenseur de taille 4 \n",
    "    la première dimension correspond au nombre d'element dans le jeu de donnée\n",
    "    le second le nombre de couleurs/channel de l'image  (ici 1 les images sont en noir et blanc)\n",
    "    le troisième et quatrième la longeur et largeur de l'image \n",
    "\n",
    "    Sortie:\n",
    "    Le jeu de donnée normalisée sous la forme d'un tenseur de taille 4\n",
    "    '''\n",
    "    \n",
    "    return Normalized\n",
    "\n",
    "restrict_train_tensors=np.array([np.array(restrict_train[i][0]) for i in range(len(restrict_train))])\n",
    "restrict_train_tensors=torch.tensor(restrict_train_tensors)\n",
    "Normalized_train=tme1.Normalize_dataset(restrict_train_tensors)\n",
    "plt.imshow(Normalized_train[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b9f52-dc43-43f7-913b-11e88ead3de7",
   "metadata": {},
   "source": [
    "## Q7: Cropper les données d'entrées\n",
    "\n",
    "1. Que fait v2.RandomCrop?\n",
    "reference: https://pytorch.org/vision/main/generated/torchvision.transforms.RandomCrop.html\n",
    "\n",
    "2. Definir un fonction RandomCrop_dataset qui applique un RandomCrop, de la taille qui vous conviendra, à l'ensemble des images d'un jeu de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe910df-0c63-4308-8ad4-756c8e5e83bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def RandomCrop_dataset(dataset):\n",
    "    ''' \n",
    "    Entrée:\n",
    "    Le jeu de donnée de tenseurs, c'est à dire un tenseur de taille 4 \n",
    "    la première dimension correspond au nombre d'element dans le jeu de donnée\n",
    "    le second le nombre de couleurs/channel de l'image  (ici 1 les images sont en noir et blanc)\n",
    "    le troisième et quatrième la longeur et largeur de l'image \n",
    "\n",
    "    Sortie:\n",
    "    Le jeu de donnée apres application de RandomCrop_dataset sous la forme d'un tenseur de taille 4\n",
    "    '''\n",
    "    \n",
    "    return Cropped\n",
    "\n",
    "Cropped_train=tme1.RandomCrop_dataset(restrict_train_tensors)\n",
    "plt.imshow(Cropped_train[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7063da3-9f35-4bb6-bc75-8840a358f786",
   "metadata": {},
   "source": [
    "## Q8: À vous de choisir !\n",
    "\n",
    "Choisissez une transformation de `Transform` que nous n'avons pas expliquée et :  \n",
    "1. Expliquez ce que fait cette transformation.  \n",
    "2. Créez une fonction `Choix_transformation` qui applique cette transformation à l'ensemble du jeu de données.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440f628-deaf-4510-a2cb-4b33796728cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Choix_transformation(dataset):\n",
    "    ''' \n",
    "    Entrée:\n",
    "    Le jeu de donnée de tenseurs, c'est à dire un tenseur de taille 4 \n",
    "    la première dimension correspond au nombre d'element dans le jeu de donnée\n",
    "    le second le nombre de couleurs/channel de l'image  (ici 1 les images sont en noir et blanc)\n",
    "    le troisième et quatrième la longeur et largeur de l'image \n",
    "\n",
    "    Sortie:\n",
    "    Le jeu de donnée apres application de la transformation sous la forme d'un tenseur de taille 4\n",
    "    '''\n",
    "    \n",
    "    return Choix\n",
    "\n",
    "Choix_train=tme1.Choix_transformation(restrict_train_tensors)\n",
    "plt.imshow(Choix_train[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cc21f-cb6f-4d14-8f8b-6bda53097a5e",
   "metadata": {},
   "source": [
    "## Q9: Premier réseau de neurone "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f605b9-2703-45c9-838e-143e26e78199",
   "metadata": {},
   "source": [
    "Compléter la fonction suivante qui permet d'implémenter un réseau de neurones à deux couches qui permettra de prédire la classe des données.\n",
    "Il faut choisir ninput et noutput de manière adéquate par rapport à notre problème de classification.\n",
    "\n",
    "Reporter votre réponse dans tme1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa70bc1-35d5-427f-bf87-6bacc568d98c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Twolayers(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,ninput,noutput):\n",
    "        super(Twolayers, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(ninput, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, noutput)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, input):\n",
    "       ''' A compléter '''\n",
    "       \n",
    "        return output\n",
    "ninput=  ''' A compléter '''\n",
    "noutput= ''' A compléter '''\n",
    "\n",
    "twolayers = tme1.Twolayers(ninput,noutput)\n",
    "twolayers(restrict_train_tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb09c7-7ddf-4d43-b898-bc6d5774949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchview import draw_graph\n",
    "model_graph = draw_graph(twolayers, input_size=(1,1,28,28), expand_nested=True)\n",
    "model_graph.visual_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
