{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzMJ2QtGxpkq"
   },
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME 5 et 6 </h1>\n",
    "<br>\n",
    "L’objectif de ce TME est:\n",
    "<br>\n",
    "<ul>\n",
    "<li> implémenter l'algorithme de Viterbi et l'estimation des paramètres (en utilisant le Viterbi training)\n",
    "pour l'exemple du occasionally dishonest casino.   </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p><b>Soumission</b></p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME5_6.ipynb pour TME_5_6_NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre via moodle </li>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiohDpWCxpkv"
   },
   "source": [
    "Nom etudiant 1 :\n",
    "<br>\n",
    "Nom etudiant 2 :\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6n5Srpuxpkv"
   },
   "source": [
    "### Introduction\n",
    "Un casino parfois malhonnête (*occasionally dishonest casino*) utilise 2 types de pièces : **fair** et **unfair**.\n",
    "\n",
    "Hidden States: S = \\{F,U\\} (Fair, Unfair)\n",
    "\n",
    "La matrice de transition entre les états cachés est :\n",
    "\n",
    "P =\n",
    "\\begin{pmatrix}\n",
    "0.99 & 0.01 \\\\\n",
    "0.05 & 0.95\n",
    "\\end{pmatrix}\n",
    "\n",
    "\n",
    "<br> Et la condition initiale $\\pi^{(0)} = (0.999,0.001)$ \n",
    "Le jeux commence presque toujours avec le pieces juste (fair).\n",
    "\n",
    "\n",
    "Obserations/Symbols: O = {H,T} (head, tail):\n",
    "\n",
    "Les probabilités d'émission des symboles:\n",
    "\n",
    "\\begin{aligned}\n",
    "e_F(H) &= 0.5 \\quad & e_F(T) &= 0.5 \\\\\n",
    "e_U(H) &= 0.9 \\quad & e_U(T) &= 0.1\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKz1fEeIxpkw"
   },
   "source": [
    "<b>Exercice 1</b>:\n",
    "<u>Simulation</u>: Écrire une fonction qui simule $T$ jets de pièces. \n",
    "La fonction renverra un tableau à deux colonnes correspondant \n",
    "aux valeurs simulées pour les états cachés $X_t$ \n",
    "(type de dés utilisée, “F” ou “U”) et aux symboles observées $Y_t$ \n",
    "(résultat du jet de dés, “H” ou “T”). On simulera une séquence\n",
    "de longueur 2000 qu'on gardera pour les applications ultérieures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txZ2YCPbxpkx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#states\n",
    "S = { 0:'F',1 :'U'}\n",
    "\n",
    "#transition probability matrix\n",
    "Pij = np.array([[0.99,0.01], [0.05,0.95]])\n",
    "\n",
    "#emision symbols \n",
    "O = {0:'H', 1: 'T'}\n",
    "\n",
    "#emission probability matrix\n",
    "Ei = np.array([[0.5,0.5], [0.9,0.1]]) #ça aurait dû être Eio\n",
    "\n",
    "# initial Condition\n",
    "pi0=np.array([0.999,0.001])\n",
    "\n",
    "#number of jets\n",
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OIqLuzAxpkz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Fonction qui simule T jets de pieces\n",
    "def jets(T, pi0, Ei, Pij):\n",
    "    \"\"\"\n",
    "      simulation of occasionally dishonest casino\n",
    "      input1 T: number of jets\n",
    "      input2 pi0: initial condition\n",
    "      input3 Ei: emission probability matrix\n",
    "      input4 Pij: transition probability matrix\n",
    "      output1 jetsRes: matrix |TxN_states| containing simulations\n",
    "    \"\"\"\n",
    "\n",
    "    # Creation du tableau\n",
    "    jetsRes = np.zeros((T, len(Pij)),dtype=int)\n",
    "    \n",
    "   \n",
    "    return jetsRes\n",
    "\n",
    "\n",
    "\n",
    "def printSimulation(simulation):\n",
    "    for t in simulation : \n",
    "        print (t[0], t[1])\n",
    "\n",
    "\n",
    "jetsRes = jets(T, pi0, Ei, Pij)\n",
    "printSimulation(jetsRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpGzwVdIxpk0"
   },
   "source": [
    "<b>Exercice 2</b>: <u>Algorithme de Viterbi </u>: Écrire une fonction qui permet\n",
    "de déterminer la séquence $(i^\\star_t)_{t=0:T}$ d'états cachés\n",
    "plus probable, ainsi que sa probabilité. En tant qu'observations, utiliser le résultat de la \n",
    "simulation (2éme colonne) de la question 1. Comparer $(i^\\star_t)_{t=0:T}$ avec\n",
    "les vrais états cachés (1ère colonne de la simulation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCN_KQ-txpk1"
   },
   "outputs": [],
   "source": [
    "# Algorithme de Viterbi\n",
    "import operator\n",
    "\n",
    "def viterbi(simulations, Pij, Ei, pi0, enLog):\n",
    "    \"\"\"\n",
    "    Implement Viterbi algorithm\n",
    "    input1 simulations: matrix |TxN_states| containing simulations\n",
    "    input4 Pij: transition probability matrix\n",
    "    input3 Ei: emission probability matrix\n",
    "    input4 pi0: initial condition\n",
    "    input6 enLog: bool, when True we apply log to avoid underflow\n",
    "    output1 i_star: most problable path\n",
    "    output2 prob: probability associated to the most problable path\n",
    "    \"\"\"\n",
    "\n",
    "    obs = simulations[:,1]\n",
    "    nS = len(Pij) #Nombre d'états\n",
    "    T = len(obs) #Nombre d'observations (longueur des observations)\n",
    "\n",
    "    i_star = np.zeros((T))\n",
    "    prob = 1\n",
    "\n",
    "\n",
    "    return i_star, prob\n",
    "\n",
    "def analyseResultats(simulations, estimation):    \n",
    "    \"\"\"\n",
    "    Compare expected and obtained paths\n",
    "    input1 simulations: expected path\n",
    "    input2 estimation: obtained path\n",
    "    output1 error: percentage error\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "i_est, p_est = viterbi(jetsRes, Pij, Eij, pi0, False)\n",
    "error = analyseResultats(jetsRes, i_est)\n",
    "print('erreur d\\'estimation de viterbi:')\n",
    "print(error,'%')\n",
    "print('Probabilité estimé:')\n",
    "print(p_est)\n",
    "\n",
    "i_est, p_est = viterbi(jetsRes,Pij,Eij,pi0,True)\n",
    "error = analyseResultats(jetsRes, i_est)\n",
    "print('erreur d\\'estimation de viterbi:')\n",
    "print(error,'%')\n",
    "print('Probabilité estimé:')\n",
    "print(p_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7NimDYwxpk2"
   },
   "source": [
    "<b>Exercice 3</b>: <u>Estimation des paramètres</u>\n",
    "<br>\n",
    "3.1) Écrire une fonction qu'utilise tous les résultats de la simulation\n",
    "(états et symboles) pour estimer $P_{ij}$, $E_i(O)$ et pi_0. Attention, pour éviter les probabilités à zéro nous allons utiliser les pseudo-count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "msq33Rxjxpk2"
   },
   "outputs": [],
   "source": [
    "# Estimation de Parametres par contage\n",
    "def nombresOccurrence(simulation, nS, nO):\n",
    "    \"\"\"\n",
    "    Parameter estimation\n",
    "    input1 simulation: matrix |TxN_states| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Pij_est: transition probability matrix\n",
    "    output2 Ei_est: emission probability matrix\n",
    "    output3 pi0_est: initial condition \n",
    "    \"\"\"\n",
    "\n",
    "    Pij_est = np.ones((nS,nS)) #pseudo-count = 1\n",
    "    Ei_est = np.ones((nS,nO))  #pseudo-count = 1\n",
    "    pi0_est = np.ones((nS))\n",
    "\n",
    "    etat_seq = simulation[:,0]\n",
    "    obs_seq = simulation[:,1]\n",
    "    T = len(obs_seq)\n",
    "\n",
    "    # estimate Pij_est and Ei_est using frequency ...\n",
    "\n",
    "\n",
    "    # to estimate pi0_est\n",
    "    pi0_est = np.ones((nS)) / 1000 # Il n'y a pas assez d'informations pour π\n",
    "    pi0_est[etat_seq[0]] = 0.999  # On doit répéter le procès de génération de séquence de plusieurs fois pour obtenir le meilleur π\n",
    "    \n",
    "    # normalize Pij_est, Ei_est, pi0_est .....\n",
    "\n",
    "    return Pij_est, Ei_est, pi0_est\n",
    "\n",
    "\n",
    "Pij_est, Ei_est ,pi0_est = nombresOccurrence(jetsRes,2,2)\n",
    "\n",
    "print('Pij estimé:')\n",
    "print(Pij_est)\n",
    "print('\\nEio estimé:')\n",
    "print(Ei_est)\n",
    "print('\\npi0 estimé:')\n",
    "print(pi0_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-ZYvpCgxpk3"
   },
   "source": [
    "3.2) <u> Viterbi training </u>: Écrire une fonction qui utilise\n",
    "seulement la séquence $(O_t)_{t=0:T}$ (2emme colonne de la simulation) pour estimer les\n",
    "paramètres $P_{ij}$ est $Ei(O)$. On s’arrêtera quand les différences entre les logVraissamblance est inférieur à 1e-04. Comparer les résultats de 3.1 et de 3.2 (3.2 avec plusieurs restarts,\n",
    "et avec initialisation des paramètres aléatoire).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhKsGmO2xpk4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialisation aleatoire de Pij, Eij, pi0\n",
    "def InititRandom(nS, nO):\n",
    "    \"\"\"\n",
    "    randomly initialisations \n",
    "    input1 nS: number of states\n",
    "    input2 nO: number of observations\n",
    "    output1 Pij_init: transition probability matrix\n",
    "    output2 Ei_init: emission probability matrix\n",
    "    output3 pi0_init: initial condition \n",
    "    \"\"\"\n",
    "    random.seed(10)\n",
    "\n",
    "\n",
    "    return Pij_init, Ei_init, pi0_init\n",
    "\n",
    "# Calcule log Vraissamblance\n",
    "def logLikelhihood(Pij_est,Eij_est,pi0_est,jets_est):\n",
    "    \"\"\"\n",
    "    compute Log Likelihood \n",
    "    input1 Pij: transition probability matrix\n",
    "    input2 Ei: emission probability matrix\n",
    "    input3 pi0: initial condition \n",
    "    input4 jets: matrix |Tx2| containing data\n",
    "    \"\"\"\n",
    "    etat_seq = jets[:,0]\n",
    "    obs_seq = jets[:,1]\n",
    "    T = len(obs_seq) #Nombre d'observations (longueur des observations)\n",
    "    lLikelihood = np.log(pi0[etat_seq[0]]) + np.log(Ei[etat_seq[0]][obs_seq[0]])\n",
    " \n",
    "    # ....\n",
    "\n",
    "    return lLikelihood\n",
    "\n",
    "\n",
    "def Training(jets, nS, nO):\n",
    "    \"\"\"\n",
    "    Viterbi Training\n",
    "    input1 jets: matrix |Tx2| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Pij_est: transition probability matrix\n",
    "    output2 Ei_est: emission probability matrix\n",
    "    output3 pi0_est: initial condition \n",
    "    output4 lLikelihood: log Likelihood\n",
    "    \"\"\"\n",
    "    jets_est = np.array(jets)    \n",
    "    Pij_est, Ei_est, pi0_est = InititRandom(nS, nO)\n",
    "    \n",
    "    maxIteration = 10000\n",
    "    iCount = 0\n",
    "    stopping_criterion = 1e-04 # the algo stops when the absolute difference between two consequtive likelihood calculation is lass then soppring_criteirion\n",
    "    lLikelihood = np.zeros((maxIteration))\n",
    "   \n",
    "    while(iCount < maxIteration):\n",
    "\n",
    "        # ...\n",
    "\n",
    "\n",
    "    return Pij_est, Ei_est, pi0_est, lLikelihood\n",
    "    \n",
    "#imprimer les Parametres du Viterbi Training\n",
    "Pij_est, Ei_est, pi0_est, lLikelihood = Training(jetsRes, 2, 2)\n",
    "itCount = len(lLikelihood)\n",
    "print('Le modèle est convergé après '+str(itCount)+' itérations.')\n",
    "print('\\nPij estimée:')\n",
    "print(Pij_est)\n",
    "print('\\nEij estimée:')\n",
    "print(Ei_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6B-AX8Zxpk4"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7iq2fv5xpk5"
   },
   "source": [
    "3.3) <u>Viterbi training deuxième version</u>. \n",
    "<BR>Écrivez une version de 3.2 qui:\n",
    "- part plusieurs fois (100x) d'une initialisation aléatoire desparamètres de l'HMM,\n",
    "- utilise Viterbi training pour estimer les paramètres,\n",
    "- calcul la log-vraisemblance pour les paramètres estimés,\n",
    "- sauvegarde seulement l'estimation avec la valeur maximale de lalog-vraisemblance.\n",
    "\n",
    "Qu'est-ce que vous observez?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwS987bpxpk5"
   },
   "outputs": [],
   "source": [
    "# Viterbi Training  deuxiemme version\n",
    "\n",
    "def TrainingV2(jets, nS, nO, nIterat=100):\n",
    "    \"\"\"\n",
    "    Viterbi Training version 2.0\n",
    "    input1 jets: matrix |TxN_states| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    input4 nIterat: number of iterations\n",
    "    output1 Pij_best: best transition probability matrix\n",
    "    output2 Ei_best: best emission probability matrix\n",
    "    output3 pi0_best: best initial condition \n",
    "    output4 lLikelihood_best: best log Likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    Pij_best = []\n",
    "    Ei_best = []\n",
    "    pi0_best = []\n",
    "    lLikelihood_best = -10000\n",
    "\n",
    "\n",
    "    return Pij_best, Ei_best, pi0_best, lLikelihood_best\n",
    "    \n",
    "\n",
    "# Imprimer les Parametres du Viterbi Training deuxiemme version\n",
    "nIterat = 100\n",
    "Pij_best, Ei_best, pi0_best, lLikelihood_best = TrainingV2(jetsRes, 2, 2, nIterat)\n",
    "\n",
    "print('Meilleur Pij estimée:');\n",
    "print(Pij_best)\n",
    "print('\\nMeilleur Eij estimée:')\n",
    "print(Ei_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4EHk9MKxpk6"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark:\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TME5_6_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
