# -*- coding: utf-8 -*-
"""tme_solo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjsDunmhgr1NCLbhX6muUEe1BtuTbwz1
"""

'''
# Evaluation 9-5-24 Cours Deep-Life TME-solo-2

Nom: tantouch

Prénom: maher

Numéro Etudiant: 21219364


'''

from matplotlib import cm
import torch
import torch; torch.manual_seed(0)
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import numpy as np
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200
import torchvision
from torchvision import datasets, transforms
from torch.utils.data import Subset
from torch.utils.data import random_split

#Q1
def question1(training_data_fashion):
    '''entrée: training_data_fashion
       sortie: affiche la réponse sous forme de texte'''

    reponse = """
Les images dans training_data_fashion sont des photos de 28x28 pixels en noir et blanc, qui représentent des fringues comme des t-shirts, des pantalons, des robes, etc. Chaque image a un label qui dit à quelle catégorie de vêtement elle appartient.

Le dataset training_data_fashion contient 60 000 images pour l'entraînement. Il y a 10 classes différentes, correspondant à 10 types de vêtements, avec des labels allant de 0 à 9.

Chaque échantillon contient deux choses :

L’image (un tableau de 28x28 pixels avec des valeurs entre 0 et 1, représentant l’intensité lumineuse de chaque pixel),
Le label est un entier entre 0 et 9 qui indique quel type de vêtement et les différents label semblent être : Tee-Shirt ; Chaussure ; Robe ; Pull etc.
    """

    print(reponse)

def question2(training_data_fashion, test_data_fashion):
    ''' entrée training_data_fashion: le train de FashionMnist
        entrée test_data_fashion: le test de FashionMnist
        sortie training_data_small: le jeu de données train qui contient 1/10 du train de FashionMnist
        sortie test_data_small: le jeu de données test qui contient 1/10 du test de FashionMnist'''

    #on commznce par rcuperer les indices pour chaque classes
    def obtenir_indices_par_classe(jeu_donnees):
        indices_par_classe = {i: [] for i in range(10)}
        for i, (_, label) in enumerate(jeu_donnees):
            indices_par_classe[label].append(i)
        return indices_par_classe

    #ss ensemble respectant la proportion de 10 %
    def creer_jeu_donnees_reduit(jeu_donnees, fraction=0.1):
        indices_par_classe = obtenir_indices_par_classe(jeu_donnees)
        indices_reduits = []

  #on prend une fraction d'indice de chaque classe
        for label, indices in indices_par_classe.items():
            nb_indices = int(len(indices) * fraction)
            indices_reduits.extend(np.random.choice(indices, nb_indices, replace=False))  # Sélection sans remplacement

        return Subset(jeu_donnees, indices_reduits)

    #on attribue au variable training_data_small
    training_data_small = creer_jeu_donnees_reduit(training_data_fashion)
    test_data_small = creer_jeu_donnees_reduit(test_data_fashion)

    return training_data_small, test_data_small

def noise(x,p=0.1):
    '''entrée x: image d'entrée
       entrée p: niveau de bruit
       sortie image_bruitee: image bruitée
    '''

    x_flat = x.view(-1)

  #on dztrmine nombre de pixels a bruiter
    N = x_flat.size(0)
    n_pixels = int(p * N)

  #choix des n_pixels indices
    indices = torch.randint(0, N, (n_pixels,))


    x_flat[indices] = 1.0

    image_bruitee = x_flat.view(x.size())

    return image_bruitee

def question5(training_data_small,p=0.1):
    ''' entrée training_data_small: 1/10 du train de FashionMnist
        entrée p: niveau de bruit par defaut 0.1
        sortie training_data_small_noized: les couples d'images et label issus de training_data_small mais avec des images bruitées.
    '''
    training_data_small_noized = []

    for image, label in training_data_small:

        image_bruitee = noise(image, p)

        training_data_small_noized.append((image_bruitee, label))

    return training_data_small_noized

def train(autoencoder, data, epochs=20, lr=0.001):
    opt = torch.optim.Adam(autoencoder.parameters(), lr=lr)
    criterion = nn.MSELoss()  #Mean Squared Error Loss
    losses = []

    for epoch in range(epochs):
        loss_e = 0
        for x, y in data:
            x_noised = noise(x)  #zn applique du bruit
            opt.zero_grad()
            reconstructed = autoencoder(x_noised)
            loss = criterion(reconstructed, x)
            loss.backward()  #backpropagation
            opt.step()  #on remet à jour les parametres

            loss_e += loss.item()  #on ajoute la perte totale de cette epoque

        losses.append(loss_e / len(data))  #moyenne des pertes
    return autoencoder, losses


def question6(training_data_small_noized, autoencoder, latent_dims, input_dim, batch_size=128, epochs=20, lr=0.001):
    data = torch.utils.data.DataLoader(training_data_small_noized, batch_size=batch_size, shuffle=True)
    autoencoder, losses = train(autoencoder, data, epochs=epochs, lr=lr)
    plt.plot(losses)  #affichage
    plt.title('evolution de la perte durant l\'entraînement')
    plt.xlabel('epochs')
    plt.ylabel('MSEL')
    plt.show()

def question7(training_data_small_noised):
    '''entré training_data_small_noized: le jeu de donnée bruité
       sortie train: 90% du jeu de donnée training_data_small_noized
       sortie valid: 10% du jeu de donnée training_data_small_noized'''

    train_size = int(0.9 * len(training_data_small_noised))
    valid_size = len(training_data_small_noised) - train_size

    train, valid = random_split(training_data_small_noised, [train_size, valid_size])

    return train, valid

def question8(train1,valid1,input_dim,batch_size=128, epochs=20):
   ''' entrée train1: le jeu de donnée train qui correspond à 90% de training_data_small_noized
        entrée valid1: le jeu de donnée de validation
        entrée input_dim: la longeur des images
        entrée batch_size: la taille des batch
        entrée epochs: le nombre d'epochs
        sortie losses: une liste pour chaque hyperparametre contenant une sous list [latent,lr,loss]
        latent étant la taille du latent, lr le learning rate et
        loss étant la valeur de la loss sur le jeu de donnée de validation pource jeu d'hyperparamètres
    '''
    output = []
    latent_dims_range = range(2, 11, 2)
    lr_range = [0.0005, 0.001, 0.0015]

    for latent_dims in latent_dims_range:
        for lr in lr_range:
            autoencoder = Autoencoder(latent_dims, input_dim)
            autoencoder, losses = train(autoencoder, torch.utils.data.DataLoader(train1, batch_size=batch_size), epochs=epochs, lr=lr)

            autoencoder.eval()
            total_loss = 0
            with torch.no_grad():
                data_loader = torch.utils.data.DataLoader(valid1, batch_size=batch_size, shuffle=False)
                for x, _ in data_loader:
                    x_noisy = noise(x)
                    reconstructed = autoencoder(x_noisy)
                    loss = F.mse_loss(reconstructed, x)
                    total_loss += loss.item()

            output.append([latent_dims, lr, total_loss / len(valid1)])

    return output

def best_hyper_param(losses):
    '''entrée losses: les tuples hyperparamètres et valeur de la loss
       sortie latent_dims_val,lr_val: les hyperparamètres correspondant à la loss la plus basse'''
    min_loss = float('inf')  #pour initialiser le loss
    latent_dims_val = lr_val = None  # on initialise les var des meilleurs hyperparam
    for loss_tuple in losses:  #pzrcout des differentes combi possible
        latent_dims, lr, loss = loss_tuple
        if loss < min_loss:  #si on trouve une loss minimale alors :
            min_loss = loss
            latent_dims_val = latent_dims
            lr_val = lr
    return latent_dims_val, lr_val

def question9(training_data_small_noised, input_dim, latent_dims_val, lr_val, batch_size=128, epochs=20):
    '''
        sortie encodeur_trained: l'encodeur de l'autoencodeur entrainé sur training_data_small_noised avec les hyperparamètres optimaux.
    '''

    autoencoder = Autoencoder(latent_dims_val, input_dim)
    autoencoder, losses = train(autoencoder, torch.utils.data.DataLoader(training_data_small_noised, batch_size=batch_size), epochs=epochs, lr=lr_val)  #pour entrainement
    return autoencoder.encoder  #renvoie l'encodeur du modèle entraîné

