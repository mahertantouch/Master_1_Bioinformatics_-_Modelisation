{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0163aa-879e-4ca7-89eb-eddc62ef0f2f",
   "metadata": {},
   "source": [
    "# Consignes\n",
    "\n",
    "## Document à rendre\n",
    "Le document tme_solo.py est le document à rendre. Il doit être rendu de manière à ce qu'il soit facile à lire, et qu'il soit facile de\n",
    "repérer et de lire vos réponses. Si ce n'est pas le cas, des points vous seront retirés, ceci pouvant aller jusqu'à l'intégralité \n",
    "des points pour la question.\n",
    "\n",
    "Important!! Distinguez bien les différentes questions dans votre code .py pour qu'il soit facile de comprendre à quelle question correspond votre réponse, si ce n'est pas clair vous prennez le risque que la réponse ne soit pas prise en compte\n",
    "\n",
    "Mettez bien vos nom dans vos fichiers .py\n",
    "    \n",
    "\n",
    "## Documents autorisés\n",
    "\n",
    "Voici les consignes pour le TME-solo-2:\n",
    "Vous n'êtes pas autorisé à utiliser d'autres ressources que celles qui vous sont fournies sur Moodle au moment de l'examen. Vous pouvez utiliser les TME que vous avez déjà mis sur Moodle, c'est-à-dire les rendus de TME. Vous pouvez utiliser vos propres ordinateurs.\n",
    "Vous ne pouvez pas utiliser Internet autrement que pour accéder à Moodle. Si cette consigne n'est pas respectée, cela signifie automatiquement un zéro pour votre copie. \n",
    "\n",
    "\n",
    "**Si vous avez la moindre question sur le sujet ou des interogations vis à vis de ce que vous pouvez et ne pas faire pendant cette épreuve, demandez nous.**\n",
    "\n",
    "\n",
    "Aidez-vous de la fonction help(***), où *** doit être remplacé par l'objet,la fonction... pour lequel vous souhaitez avoir plus d'informations.\n",
    "\n",
    "## Indication sur les fonctions et classes qui peuvent être utilisées:\n",
    "\n",
    "- torch.nn.functional.relu\n",
    "- torch.sigmoid\n",
    "- nn.Linear\n",
    "- torch.sigmoid\n",
    "- matplotlib.pyplot.scatter\n",
    "- numpy.linspace\n",
    "\n",
    "#### Le bareme est donné à titre indicatif\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93af808e-53a0-4cab-9623-20d8563a6212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import cm\n",
    "import torch; torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467156fe-f6c0-4181-9337-1bc548a23708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tme_solo as tme\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274cc11d-36a8-4ea5-a29b-04f0df62bb5d",
   "metadata": {},
   "source": [
    "# Partie 0: Prétaitement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04fb1a5f-f725-42f0-9885-1b3d86dca8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data= datasets.MNIST(root=\"data\",train=True,download=True,transform=transforms.ToTensor())\n",
    "test_data = datasets.MNIST(root=\"data\",train=False,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d5942-1946-4ecd-9cd6-847eacb65436",
   "metadata": {},
   "source": [
    "### Q0.1 (1pts)\n",
    "Créez un jeu de données, training_data_small, qui ne contient que 1/6 des données de MNIST train, en vous assurant de respecter plus ou moins\n",
    "les proportions des données par classes de MNIST train. Le jeu de données training_data_small que vous retournerez doit être constitué de\n",
    "tenseurs (torch.Tensor) : c'est-à-dire que les images apparaissent en format torch.Tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bdf1d-45af-4dc8-aee9-18fce36f72c4",
   "metadata": {},
   "source": [
    "### Q0.2 (1pts)\n",
    "\n",
    "Question \"ouverte\": \n",
    "\n",
    "Effectuer un prétraitement des données qu'il vous semble pertinent de faire en justifiant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c5203a-9b99-4d18-80cf-de32202e6a80",
   "metadata": {},
   "source": [
    "# Partie I: Autoencodeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6356ca-9a79-4289-bdc6-2ef08c65e45b",
   "metadata": {},
   "source": [
    "### Q1.1 (3pts)\n",
    "Implémentez un auto-encodeur dont le latent sera de taille `latent_dims`=2 et qui sera constitué de deux blocs: \n",
    "\n",
    "- un encodeur constitué de :\n",
    "  - un layer linéaire dont la dimension de sortie est 80 avec une fonction d'activation ReLU\n",
    "  - un layer linéaire avec une fonction d'activation ReLU\n",
    "  \n",
    "- un décodeur constitué de :\n",
    "  - un layer linéaire de taille de sortie 80 avec une fonction d'activation ReLU\n",
    "  - un layer linéaire avec une activation sigmoide\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a485ed-7bd0-4717-be07-b72b85bdf85d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q1.2 (3pts)\n",
    "Faites des batch de taille 128 et entraînez votre autoencodeur pendant 30 epochs avec comme loss la Mean Square Error. Représentez l'évolution de la loss au cours de l'entraînement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19e406a-76bf-49ac-9ccd-7ac54d034385",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Q1.3 (3pts)\n",
    "Rappel `latent_dims`=2. \n",
    "\n",
    "Faites une recherche des meilleurs hyperparamètres en justifiant votre méthodologie: c'est à dire les paramètres que vous allez faire variés et en prétant attention au jeu de donné que vous allez considérer pour comparer vos modèles entrainés. \n",
    "\n",
    "Selectionnez les hyperparamètres optimaux et indiquez les dans vote .py, en justifiant. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703e1ad-e8cf-4cd4-ae6d-1e7136947e7a",
   "metadata": {},
   "source": [
    "### Q1.4 (2pts)\n",
    "Affichez une visualisation des représentations des données dans l'espace latent, c'est-à-dire en sortie de l'encodeur. Choisissez une couleur différente par classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2af5f5-2d02-4289-9969-85915e2ff9f7",
   "metadata": {},
   "source": [
    "### Q1.5 (2pts)\n",
    "Trouvez un rectangle dans l'espace latent qui contient au moins 90 % des données et découpez ce carré en une grille\n",
    "régulière de taille 10*10 (10 valeurs possibles en abscisse et 10 en ordonnée). Chaque nœud de cette grille \n",
    "est un vecteur de l'espace latent. Affichez les images générées par le décodeur à partir de ces points/nœuds \n",
    "dans le latent. Représentez les images en sortie du décodeur sous la forme d'un tableau facilement compréhensible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f51cb1-c4e1-47c9-8e41-424df63b301b",
   "metadata": {},
   "source": [
    "# Partie II: VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b982d-6b5d-4223-bee7-58fa6319f28e",
   "metadata": {},
   "source": [
    "#### Q2.1 (8pts)\n",
    "\n",
    "1)Implémentez un autoencodeur variationnel dont,\n",
    "\n",
    "- l'encodeur est constitué en ce qui concerne la moyenne mu de :\n",
    "  - un layer linéaire de taille de la dimension d'entrée et de sortie 128 avec une fonction d'activation ReLU\n",
    "  - un layer linéaire de taille 128 en entrée\n",
    "\n",
    "- l'encodeur est constitué en ce qui concerne l'écart type sigma de :\n",
    "  - un layer linéaire de taille de la dimension d'entrée et de sortie 128 avec une fonction d'activation ReLU\n",
    "  - un layer linéaire de taille 128 en entrée suivi d'une fonction exponentielle\n",
    "\n",
    "Le premier layer du réseau pour mu et sigma peut être partagé, c'est-à-dire qu'ils partagent le meme premier layer.\n",
    "\n",
    "Comme dans la Partie I :\n",
    "- le décodeur est constitué de :\n",
    "  - un layer linéaire de taille de sortie 128 avec une fonction d'activation ReLU\n",
    "  - un layer linéaire de taille d'entrée 128 avec une sigmoide\n",
    "\n",
    "\n",
    "Indication : vous pouvez vous aider du document 'rappel.pdf' pour implémenter le VAE.\n",
    "\n",
    "\n",
    "2)Faites des batch de taille 128 et entraînez votre autoencodeur pendant 30 epochs avec comme loss la Mean Square Error. Représentez l'évolution de la loss au cours de l'entraînement. Vous êtes libre de choisir la régularisation que vous souhaitez.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108219dd-6e2c-4580-9ff8-8127c34e85ca",
   "metadata": {},
   "source": [
    "# Partie III: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abf82b4-9366-43f6-8245-bb7784327e25",
   "metadata": {},
   "source": [
    "### Q3.1 (3pts)\n",
    "Exploitez les représentations compressées des images données par les encodeurs de la première partie et de la seconde partie (VAE) pour entraîner un perceptron à deux couches, chaque couche étant un réseau linéaire avec ReLU. On veut entraîner seulement ces deux couches supplémentaires sans modifier les poids de l'encodeur. Comparez les accuracy sur le jeu de données test des deux encodeurs.\n",
    "\n",
    "Indicate that some weights can be frozen (no gradient descent over those weights) with the following command\n",
    "\n",
    "```python\n",
    " param.requires_grad = False\n",
    " ````\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
