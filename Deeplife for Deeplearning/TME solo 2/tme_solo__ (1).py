# -*- coding: utf-8 -*-
"""tme_solo__

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H7GznEoJlX6s2HZJdehyFJMGu7_MBuPM

Nom : Tantouch ; Prénom : Maher
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
from sklearn.decomposition import PCA
from matplotlib import cm
import torch; torch.manual_seed(0)
import torch.nn as nn
import torch.nn.functional as F
import torch.utils
import torch.distributions
import numpy as np
import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 200
import torchvision
from torchvision import datasets, transforms

""" Question 0.1 """

torch.manual_seed(0)

num_classes = 10
class_indices = [[] for _ in range(num_classes)]

for idx in range(len(training_data)):
    _, label = training_data[idx]
    class_indices[label].append(idx)

subset_per_class = [len(indices) // 6 for indices in class_indices]

selected_indices = []
for c in range(num_classes):
    indices = torch.tensor(class_indices[c])
    indices = indices[torch.randperm(len(indices))][:subset_per_class[c]]
    selected_indices.append(indices)

selected_indices = torch.cat(selected_indices)

images = []
labels = []

for idx in selected_indices:
    img, label = training_data[idx.item()]
    images.append(img)
    labels.append(label)

images_tensor = torch.stack(images)
labels_tensor = torch.tensor(labels)

training_data_small = list(zip(images_tensor, labels_tensor))

""" Question 0.2 """

""" Question 1.1 """

latent_dims = 2

class Autoencoder(nn.Module):
    def __init__(self):
        super().__init__()
        # Encodeur
        self.encoder_fc1 = nn.Linear(28*28, 80)
        self.encoder_fc2 = nn.Linear(80, latent_dims)
        # Décodeur
        self.decoder_fc1 = nn.Linear(latent_dims, 80)
        self.decoder_fc2 = nn.Linear(80, 28*28)

    def forward(self, x):
        x = x.view(x.size(0), -1)  #aplatissement des images
        x = F.relu(self.encoder_fc1(x))
        x = F.relu(self.encoder_fc2(x))
        x = F.relu(self.decoder_fc1(x))
        x = torch.sigmoid(self.decoder_fc2(x))
        x = x.view(x.size(0), 1, 28, 28)  #reshape en image
        return x


""" Question 1.2 """

batch_size = 128
epochs = 30
learning_rate = 1e-3

train_loader = DataLoader(training_data_small, batch_size=batch_size, shuffle=True)

model = Autoencoder()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
criterion = nn.MSELoss()

losses = []

for epoch in range(epochs):
    model.train()
    running_loss = 0
    for images, _ in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, images)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    epoch_loss = running_loss / len(train_loader.dataset)
    losses.append(epoch_loss)
    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.6f}")

plt.plot(range(1, epochs+1), losses)
plt.xlabel("epoch")
plt.ylabel("MSE Loss")
plt.title("Evolution de la loss durant l'entrainement")
plt.show()

""" Question 1.3 """

from torch.utils.data import random_split

n_train = int(0.8 * len(training_data_small))
n_val = len(training_data_small) - n_train
train_subset, val_subset = random_split(training_data_small, [n_train, n_val])

def train_autoencoder(batch_size, lr, hidden_size):
    class AutoencoderCustom(nn.Module):
        def __init__(self):
            super().__init__()
            self.encoder_fc1 = nn.Linear(28*28, hidden_size)
            self.encoder_fc2 = nn.Linear(hidden_size, latent_dims)
            self.decoder_fc1 = nn.Linear(latent_dims, hidden_size)
            self.decoder_fc2 = nn.Linear(hidden_size, 28*28)

        def forward(self, x):
            x = x.view(x.size(0), -1)
            x = F.relu(self.encoder_fc1(x))
            x = F.relu(self.encoder_fc2(x))
            x = F.relu(self.decoder_fc1(x))
            x = torch.sigmoid(self.decoder_fc2(x))
            x = x.view(x.size(0), 1, 28, 28)
            return x

    model = AutoencoderCustom()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.MSELoss()
    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)

    epochs = 30
    for epoch in range(epochs):
        model.train()
        for images, _ in train_loader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, images)
            loss.backward()
            optimizer.step()

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for images, _ in val_loader:
            outputs = model(images)
            val_loss += criterion(outputs, images).item() * images.size(0)
    val_loss /= len(val_loader.dataset)
    return val_loss

params_grid = [
    {'batch_size': 64, 'lr': 1e-3, 'hidden_size': 40},
    {'batch_size': 128, 'lr': 1e-3, 'hidden_size': 80},
    {'batch_size': 256, 'lr': 1e-4, 'hidden_size': 120},
]

results = []
for params in params_grid:
    val_loss = train_autoencoder(**params)
    results.append((val_loss, params))

best_loss, best_params = min(results, key=lambda x: x[0])
print(f"meilleure perte de validation: {best_loss:.6f} avec les paramètres: {best_params}")


""" Question 1.4 """

model.eval()

latents = []
labels = []

with torch.no_grad():
    for images, targets in torch.utils.data.DataLoader(training_data_small, batch_size=128):
        x = images.view(images.size(0), -1)
        h1 = F.relu(model.encoder_fc1(x))
        latent_vec = F.relu(model.encoder_fc2(h1))  #sortie encodeur (latent_dim=2)
        latents.append(latent_vec)
        labels.append(targets)

latents = torch.cat(latents).numpy()
labels = torch.cat(labels).numpy()

plt.figure(figsize=(8, 6))
scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab10', s=10)
plt.colorbar(scatter, ticks=range(10))
plt.xlabel("latent dimension 1")
plt.ylabel("latent dimension 2")
plt.title("observation des représentations latentes par classe")
plt.show()


""" Question 1.5 """

model.eval()

latents = []
with torch.no_grad():
    for images, _ in torch.utils.data.DataLoader(training_data_small, batch_size=128):
        x = images.view(images.size(0), -1)
        h1 = F.relu(model.encoder_fc1(x))
        latent_vec = F.relu(model.encoder_fc2(h1))
        latents.append(latent_vec)

latents = torch.cat(latents).numpy()

x_min, x_max = np.percentile(latents[:, 0], [5, 95])
y_min, y_max = np.percentile(latents[:, 1], [5, 95])

x_grid = np.linspace(x_min, x_max, 10)
y_grid = np.linspace(y_min, y_max, 10)
grid_points = np.array([[x, y] for y in y_grid for x in x_grid])

latent_nodes = torch.tensor(grid_points, dtype=torch.float32)

with torch.no_grad():
    decoded = model.decoder_fc1(latent_nodes)
    decoded = F.relu(decoded)
    decoded = model.decoder_fc2(decoded)
    decoded = torch.sigmoid(decoded)
    decoded = decoded.view(-1, 28, 28).numpy()

fig, axes = plt.subplots(10, 10, figsize=(10, 10))
for i, ax in enumerate(axes.flat):
    ax.imshow(decoded[i], cmap='gray')
    ax.axis('off')
plt.suptitle("images produites par le decodeur depuis la grille latente 10x10")
plt.tight_layout()
plt.show()


""" Question 2.1 """

class VAE(nn.Module):
    def __init__(self, input_dim=28*28, latent_dim=2):
        super(VAE, self).__init__()
        self.shared_fc1 = nn.Linear(input_dim, 128)
        self.mu_fc = nn.Linear(128, latent_dim)
        self.sigma_fc = nn.Linear(128, latent_dim)
        self.decoder_fc1 = nn.Linear(latent_dim, 128)
        self.decoder_fc2 = nn.Linear(128, input_dim)

    def encode(self, x):
        h1 = F.relu(self.shared_fc1(x))
        mu = self.mu_fc(h1)
        log_sigma = self.sigma_fc(h1)
        sigma = torch.exp(log_sigma)
        return mu, sigma

    def reparameterize(self, mu, sigma):
        eps = torch.randn_like(sigma)
        return mu + eps * sigma

    def decode(self, z):
        h3 = F.relu(self.decoder_fc1(z))
        return torch.sigmoid(self.decoder_fc2(h3))

    def forward(self, x):
        mu, sigma = self.encode(x)
        z = self.reparameterize(mu, sigma)
        x_reconst = self.decode(z)
        return x_reconst, mu, sigma



""" Question 2.2 """

batch_size = 128
epochs = 30

train_loader = DataLoader(training_data_small, batch_size=batch_size, shuffle=True)

model = VAE(input_dim=28*28, latent_dim=2)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
mse_loss = nn.MSELoss(reduction='sum')

def loss_function(recon_x, x, mu, sigma):
    MSE = mse_loss(recon_x, x)
    KL = -0.5 * torch.sum(1 + torch.log(sigma**2) - mu.pow(2) - sigma.pow(2))
    return MSE + KL

model.train()
loss_history = []

for epoch in range(epochs):
    total_loss = 0
    for batch, _ in train_loader:
        batch = batch.view(batch.size(0), -1)
        optimizer.zero_grad()
        recon_batch, mu, sigma = model(batch)
        loss = loss_function(recon_batch, batch, mu, sigma)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_loader.dataset)
    loss_history.append(avg_loss)
    print(f"epoch {epoch+1}/{epochs}, loss: {avg_loss:.4f}")

plt.plot(range(1, epochs+1), loss_history)
plt.xlabel("epoch")
plt.ylabel("loss (MSE + KL)")
plt.title("evzlution de la loss durant l'entraînement du VAE")
plt.show()



